{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import model.aotgan \n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from loss1 import loss as loss_module\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"4\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'rates':[1, 2, 4, 8],\n",
    "        'block_num':8,\n",
    "        'model':'aotgan',\n",
    "        'gan_type':\"smgan\",\n",
    "        'lrg':1e-4,\n",
    "        'lrd':1e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':8,\n",
    "        'epochs':500,\n",
    "        'data_path':'../../data/dataset/adenoma/',\n",
    "        'num_workers':4,\n",
    "        'rec_loss':'1*L1+250*Style+0.1*Perceptual'\n",
    "        }\n",
    "losses = list(params['rec_loss'].split(\"+\"))\n",
    "params['rec_loss'] = {}\n",
    "for l in losses:\n",
    "    weight, name = l.split(\"*\")\n",
    "    params['rec_loss'][name] = float(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, args,dataset):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.w = self.h = args['image_size']\n",
    "\n",
    "        # image and mask\n",
    "        self.image_path =glob(args['data_path']+dataset+'/image/*.jpg')\n",
    "        self.mask_path = [i.replace('/image','/mask') for i in self.image_path]\n",
    "\n",
    "        #augmentation\n",
    "        self.trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(args['image_size'], interpolation=transforms.InterpolationMode.NEAREST),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation((0, 45), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "                transforms.RandomResizedCrop(args['image_size']),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        random_seed = 42\n",
    "        random.seed(random_seed)  # Python의 random 함수에 대한 시드 설정\n",
    "        torch.manual_seed(random_seed)\n",
    "        image = Image.open(self.image_path[index]).convert(\"RGB\")\n",
    "        filename = os.path.basename(self.image_path[index])\n",
    "        mask = Image.open(self.mask_path[index])\n",
    "        mask = mask.convert(\"L\")\n",
    "        # augment\n",
    "        torch.manual_seed(random_seed)\n",
    "        image = F.to_tensor(self.trans(image)) * 2.0 - 1.0\n",
    "        torch.manual_seed(random_seed)\n",
    "        mask = F.to_tensor(self.trans(mask))\n",
    "        \n",
    "        return image, mask, filename\n",
    "    \n",
    "train_dataset=CustomDataset(params,'train')\n",
    "test_dataset=CustomDataset(params,'test')\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "         shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG =model.aotgan.InpaintGenerator(params).to(device)\n",
    "optimG = torch.optim.Adam(netG.parameters(), lr=params['lrg'], betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "netD = model.aotgan.Discriminator().to(device)\n",
    "optimD = torch.optim.Adam(netD.parameters(), lr=params['lrd'], betas=(params['beta1'], params['beta2']))\n",
    "rec_loss_func = {key: getattr(loss_module, key)() for key, val in params['rec_loss'].items()}\n",
    "adv_loss = getattr(loss_module, \"smgan\")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(params['epochs']):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    train_L1_loss = 0.0\n",
    "    train_Style_loss = 0.0\n",
    "    train_Perceptual_loss = 0.0\n",
    "    train_advg_loss = 0.0\n",
    "    train_advd_loss = 0.0\n",
    "    for images, masks,filename in train:\n",
    "        count+=1\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        images_masked = (images * (1 - masks).float()) + masks\n",
    "        pred_img = netG(images_masked, masks)\n",
    "        comp_img = (1 - masks) * images + masks * pred_img\n",
    "        losses = {}\n",
    "        for name, weight in params['rec_loss'].items():\n",
    "            losses[name] = weight * rec_loss_func[name](pred_img, images)\n",
    "        dis_loss, gen_loss = adv_loss(netD, comp_img, images, masks)\n",
    "        losses[\"advg\"] = gen_loss * 0.01\n",
    "        # backforward\n",
    "        optimG.zero_grad()\n",
    "        optimD.zero_grad()\n",
    "        sum(losses.values()).backward()\n",
    "        losses[\"advd\"] = dis_loss\n",
    "        dis_loss.backward()\n",
    "        optimG.step()\n",
    "        optimD.step()\n",
    "        train_L1_loss+=losses['L1'].item()\n",
    "        train_Style_loss+=losses['Style'].item()\n",
    "        train_Perceptual_loss+=losses['Perceptual'].item()\n",
    "        train_advg_loss+=losses['advg'].item()\n",
    "        train_advd_loss+=losses['advd'].item()\n",
    "        train.set_description(f\"epoch: {epoch+1}/{params['epochs']} Step: {count+1} L1 loss : {train_L1_loss/count:.4f} Style loss: {train_Style_loss/count:.4f} Perceptual loss: {train_Perceptual_loss/count:.4f} advg loss: {train_advg_loss/count:.4f} advd loss: {train_advd_loss/count:.4f}\")\n",
    "    test=tqdm(test_dataloader)\n",
    "    test_count=0\n",
    "    test_L1_loss = 0.0\n",
    "    test_Style_loss = 0.0\n",
    "    test_Perceptual_loss = 0.0\n",
    "    test_advg_loss = 0.0\n",
    "    test_advd_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks,filename in test:\n",
    "            test_count+=1\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            images_masked = (images * (1 - masks).float()) + masks\n",
    "            pred_img = netG(images_masked, masks)\n",
    "            comp_img = (1 - masks) * images + masks * pred_img\n",
    "            test_losses = {}\n",
    "            for name, weight in params['rec_loss'].items():\n",
    "                test_losses[name] = weight * rec_loss_func[name](pred_img, images)\n",
    "            dis_loss, gen_loss = adv_loss(netD, comp_img, images, masks)\n",
    "            test_losses[\"advg\"] = gen_loss * 0.01\n",
    "            test_losses[\"advd\"] = dis_loss\n",
    "            test_L1_loss+=test_losses['L1'].item()\n",
    "            test_Style_loss+=test_losses['Style'].item()\n",
    "            test_Perceptual_loss+=test_losses['Perceptual'].item()\n",
    "            test_advg_loss+=test_losses['advg'].item()\n",
    "            test_advd_loss+=test_losses['advd'].item()\n",
    "            test.set_description(f\"val_epoch: {epoch+1}/{params['epochs']} Step: {count+1} L1 loss : {test_L1_loss/count:.4f} Style loss: {test_Style_loss/count:.4f} Perceptual loss: {test_Perceptual_loss/count:.4f} advg loss: {test_advg_loss/count:.4f} advd loss: {test_advd_loss/count:.4f}\")\n",
    "    if epoch % 10 ==0:\n",
    "        ax=plt.figure(figsize=(24,8))\n",
    "        ax.add_subplot(1,3,1)\n",
    "        plt.imshow(np.transpose(images[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        ax.add_subplot(1,3,2)\n",
    "        plt.imshow(np.transpose(images_masked[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        ax.add_subplot(1,3,3)\n",
    "        plt.imshow(np.transpose(pred_img[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        plt.show()\n",
    "    torch.save(netG.state_dict(), '../../model/aot-model_endoscopy/generator_'+str(epoch)+'.pt')\n",
    "    torch.save(netD.state_dict(), '../../model/aot-model_endoscopy/discriminator_'+str(epoch)+'.pt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.figure(figsize=(24,8))\n",
    "ax.add_subplot(1,3,1)\n",
    "plt.imshow(np.transpose(images[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "ax.add_subplot(1,3,2)\n",
    "plt.imshow(np.transpose(images_masked[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "ax.add_subplot(1,3,3)\n",
    "plt.imshow(np.transpose(pred_img[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.transpose(images[0].cpu(),(1,2,0))/2+0.5).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(train_dataset[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
