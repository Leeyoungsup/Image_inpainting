{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 10:40:56.641944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import model.mat as MAT\n",
    "import os\n",
    "from glob import glob\n",
    "import model.aotgan \n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from loss1 import loss as loss_module\n",
    "from torch_utils import misc\n",
    "import copy\n",
    "from torch_utils.ops import conv2d_gradfix\n",
    "from losses.pcp import PerceptualLoss\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'rates':[1, 2, 4, 8],\n",
    "        'block_num':8,\n",
    "        'model':'aotgan',\n",
    "        'gan_type':\"smgan\",\n",
    "        'lrg':2e-3,\n",
    "        'lrd':2e-3,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':4,\n",
    "        'epochs':10000,\n",
    "        'data_path':'../../data/dataset/colon/',\n",
    "        'num_workers':4,\n",
    "        'rec_loss':'1*L1+100*Style+0.1*Perceptual'\n",
    "        }\n",
    "losses = list(params['rec_loss'].split(\"+\"))\n",
    "params['rec_loss'] = {}\n",
    "for l in losses:\n",
    "    weight, name = l.split(\"*\")\n",
    "    params['rec_loss'][name] = float(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, args,dataset):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.w = self.h = args['image_size']\n",
    "\n",
    "        # image and mask\n",
    "        self.image_path =glob(args['data_path']+dataset+'/image/*.png')\n",
    "        self.mask_path = [i.replace('/image','/mask') for i in self.image_path]\n",
    "        self.trans_1 = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((args['image_size'],args['image_size']), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "            ]\n",
    "        )\n",
    "    def trans(self,image_t,a):\n",
    "        image_t=F.to_tensor(F.rotate(self.trans_1(image_t),a))\n",
    "        return image_t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        image = Image.open(self.image_path[index]).convert(\"RGB\")\n",
    "        filename = os.path.basename(self.image_path[index])\n",
    "        mask = Image.open(self.mask_path[index])\n",
    "        mask = mask.convert(\"L\")\n",
    "        # augment\n",
    "        angle=random.randint(0, 360)\n",
    "        \n",
    "        image = self.trans(image,angle) * 2.0 - 1.0\n",
    "        mask = self.trans(mask,angle)\n",
    "        \n",
    "        return image, mask, filename\n",
    "    \n",
    "train_dataset=CustomDataset(params,'train')\n",
    "test_dataset=CustomDataset(params,'test')\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "         shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "netG = MAT.Generator(z_dim=512, c_dim=0, w_dim=512, img_resolution=512, img_channels=3).to(device)\n",
    "netD = MAT.Discriminator(c_dim=0, img_resolution=params['image_size'], img_channels=3).to(device)\n",
    "optimG = torch.optim.Adam(netG.parameters(), lr=params['lrg'], betas=(params['beta1'], params['beta2']))\n",
    "optimD = torch.optim.Adam(netD.parameters(), lr=params['lrd'], betas=(params['beta1'], params['beta2']))\n",
    "G_ema = copy.deepcopy(netG).eval()\n",
    "G_mapping=netG.mapping\n",
    "truncation_psi=1\n",
    "style_mixing_prob=0.9\n",
    "G_synthesis=netG.synthesis\n",
    "pcp = PerceptualLoss(layer_weights=dict(conv4_4=1/4, conv5_4=1/2)).to(device)\n",
    "def run_G(img_in, mask_in, z, c, sync):\n",
    "    with misc.ddp_sync(G_mapping, sync):\n",
    "        ws = G_mapping(z, c, truncation_psi=truncation_psi)\n",
    "        if style_mixing_prob > 0:\n",
    "            with torch.autograd.profiler.record_function('style_mixing'):\n",
    "                cutoff = torch.empty([], dtype=torch.int64, device=ws.device).random_(1, ws.shape[1])\n",
    "                cutoff = torch.where(torch.rand([], device=ws.device) < style_mixing_prob, cutoff, torch.full_like(cutoff, ws.shape[1]))\n",
    "                ws[:, cutoff:] = G_mapping(torch.randn_like(z), c, truncation_psi=truncation_psi, skip_w_avg_update=True)[:, cutoff:]\n",
    "    with misc.ddp_sync(G_synthesis, sync):\n",
    "        img, img_stg1 = G_synthesis(img_in, mask_in, ws, return_stg1=True)\n",
    "    return img, ws, img_stg1\n",
    "\n",
    "def run_D(img, mask, img_stg1, c, sync):\n",
    "    # if augment_pipe is not None:\n",
    "    #     # img = augment_pipe(img)\n",
    "    #     # !!!!! have to remove the color transform\n",
    "    #     tmp_img = torch.cat([img, mask], dim=1)\n",
    "    #     tmp_img = augment_pipe(tmp_img)\n",
    "    #     img, mask = torch.split(tmp_img, [3, 1])\n",
    "    with misc.ddp_sync(netD, sync):\n",
    "        logits, logits_stg1 = netD(img, mask, img_stg1, c)\n",
    "    return logits, logits_stg1\n",
    "netG.load_state_dict(torch.load('../../model/MAT_colon/generator_check.pt'))\n",
    "netD.load_state_dict(torch.load('../../model/MAT_colon/discriminator_check.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/10000 Step: 101 D loss : 1.3862 G loss: 1.5459 : 100%|██████████| 100/100 [01:58<00:00,  1.19s/it]\n",
      "epoch: 2/10000 Step: 101 D loss : 1.3864 G loss: 1.5375 : 100%|██████████| 100/100 [01:48<00:00,  1.09s/it]\n",
      "epoch: 3/10000 Step: 101 D loss : 1.3862 G loss: 1.5394 : 100%|██████████| 100/100 [01:48<00:00,  1.09s/it]\n",
      "epoch: 4/10000 Step: 51 D loss : 1.9437 G loss: 2.9892 :  50%|█████     | 50/100 [00:54<00:54,  1.09s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(params['epochs']):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    train_Dgen_loss = 0.0 #예측된 값과 실제 값 사이의 절대값 차이의 평균 계산\n",
    "    train_Ggen_loss = 0.0 # 네트워크가 생성한 이미지가 목표 스타일 이미지와 비슷한 텍스처, 색상 분포 및 시각적 패턴 비교\n",
    "    train_Dr_loss = 0.0 \n",
    "    \n",
    "    sum_loss= 1000.0\n",
    "    for images, masks,filename in train:\n",
    "        count+=1\n",
    "        images, masks = (images-0.5).to(device), masks.to(device)\n",
    "        z = torch.randn(params['batch_size'], 512).to(device)\n",
    "        c = torch.randn(params['batch_size'], 512).to(device)\n",
    "        masks=1-masks\n",
    "        images_masked = (images * (masks).float()) + (1-masks)\n",
    "        optimG.zero_grad()\n",
    "        optimD.zero_grad()\n",
    "        with torch.autograd.profiler.record_function('Gmain_forward'):\n",
    "            gen_img, _gen_ws, gen_img_stg1 = run_G(images, masks,z, c, sync=True) # May get synced by Gpl.\n",
    "            gen_logits, gen_logits_stg1 = run_D(images, masks, gen_img,c, sync=False)\n",
    "            \n",
    "            # dis_loss, gen_loss = adv_loss(netD, comp_img, images, masks)\n",
    "            # losses[\"advg\"] = gen_loss\n",
    "            # # backforward\n",
    "            loss_Gmain = torch.nn.functional.softplus(-gen_logits)\n",
    "            loss_Gmain_stg1 = torch.nn.functional.softplus(-gen_logits_stg1)\n",
    "            pcp_loss, _ = pcp(gen_img, images)\n",
    "        with torch.autograd.profiler.record_function('Gmain_backward'):\n",
    "            loss_Gmain_all = loss_Gmain + loss_Gmain_stg1 + pcp_loss\n",
    "            loss_Gmain_all.mean().mul(1).backward()      \n",
    "        # losses[\"advd\"] = dis_loss\n",
    "        # dis_loss.backward()\n",
    "        with torch.autograd.profiler.record_function('Dgen_forward'):\n",
    "            gen_img, _gen_ws, gen_img_stg1 = run_G(images, masks, z, None, sync=False)\n",
    "            gen_logits, gen_logits_stg1 = run_D(images, masks, gen_img, None, sync=False) # Gets synced by loss_Dreal.\n",
    "            loss_Dgen_stg1 = torch.nn.functional.softplus(gen_logits_stg1)\n",
    "            loss_Dgen = torch.nn.functional.softplus(gen_logits) # -log(1 - sigmoid(gen_logits))\n",
    "        with torch.autograd.profiler.record_function('Dgen_backward'):\n",
    "            loss_Dgen_all = loss_Dgen + loss_Dgen_stg1\n",
    "            loss_Dgen_all.mean().mul(1).backward()\n",
    " \n",
    "        \n",
    "        optimG.step()\n",
    "        optimD.step()\n",
    "        \n",
    "        train_Dgen_loss+=loss_Dgen_all.mean().mul(1).item()\n",
    "        train_Ggen_loss+=loss_Gmain_all.mean().mul(1).item()\n",
    "        train.set_description(f\"epoch: {epoch+1}/{params['epochs']} Step: {count+1} D loss : {train_Dgen_loss/count:.4f} G loss: {train_Ggen_loss/count:.4f} \")\n",
    "    if epoch % 50 ==5:\n",
    "        ax=plt.figure(figsize=(12,4))\n",
    "        ax.add_subplot(1,3,1)\n",
    "        plt.imshow(np.transpose((images[0]+0.5).cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        ax.add_subplot(1,3,2)\n",
    "        plt.imshow(np.transpose((images_masked[0]+0.5).cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        ax.add_subplot(1,3,3)\n",
    "        plt.imshow(np.transpose((gen_img[0]+0.5).cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    if sum_loss>(train_Dgen_loss/count+train_Ggen_loss/count):\n",
    "        sum_loss=train_Dgen_loss/count+train_Ggen_loss/count\n",
    "        torch.save(netG.state_dict(), '../../model/MAT_colon/generator_check.pt')\n",
    "        torch.save(netD.state_dict(), '../../model/MAT_colon/discriminator_check.pt')   \n",
    "torch.save(netG.state_dict(), '../../model/MAT_colon/generator.pt')\n",
    "torch.save(netD.state_dict(), '../../model/MAT_colon/discriminator.pt')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
